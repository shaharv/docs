Tutorials
---------

- Microsoft's AI School
  https://aischool.microsoft.com/en-us/home

- scikit-learn - Machine Learning in Python
  https://scikit-learn.org/stable/user_guide.html

Static Compilers and IR (legacy)
--------------------------------

- TVM: An Automated End-to-End Optimizing Compiler for Deep Learning
  https://www.usenix.org/system/files/osdi18-chen.pdf

- Glow: Graph Lowering Compiler Techniques for Neural Networks
  https://arxiv.org/pdf/1805.00907.pdf

- MLIR: Multi-Level Intermediate Representation Compiler Infrastructure
  https://llvm.org/devmtg/2019-04/slides/Keynote-ShpeismanLattner-MLIR.pdf

- Tensor Comprehensions: Framework-Agnostic High-Performance Machine Learning Abstractions
  https://arxiv.org/pdf/1802.04730.pdf

- Intel nGraph
  https://arxiv.org/pdf/1801.08058.pdf

- The Deep Learning Compiler: A Comprehensive Survey (27/2/2020)
  https://arxiv.org/pdf/2002.03794.pdf

ONNX
----

- LinaroOrg talk: SAN19-211 ONNX & ONNX Runtime
  https://www.youtube.com/watch?v=tua4ec2v2ls

- Arm talk: Scalable ML acceleration with ONNX Runtime
  https://www.youtube.com/watch?v=nRlnSy4Vbnc

DLRM
----

- DLRM: An advanced, open source deep learning recommendation model
  https://ai.facebook.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model

- DLRM Github
  https://github.com/facebookresearch/dlrm

- Paper: Deep Learning Recommendation Model for Personalization and Recommendation Systems
  https://arxiv.org/pdf/1906.00091.pdf

- Paper: The Architectural Implications of Facebook's DNN-based Personalized Recommendation
  https://arxiv.org/pdf/1906.03109.pdf

- DLRM Glow implementation
  https://github.com/pytorch/glow/blob/master/tests/unittests/RecommendationSystemTest.cpp

Neural Networks
---------------

- Neural Networks and Deep Learning - free online book
  http://neuralnetworksanddeeplearning.com

- Gradient Descent with Backpropagation
  http://outlace.com/Gradient-Descent.html

- The Matrix Calculus You Need For Deep Learning
  https://explained.ai/matrix-calculus/index.html

- The Cross-entropy loss function (Wikipedia)
  https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression

- Paper: ADAM: A method for stochastic optimization
  https://arxiv.org/pdf/1412.6980.pdf

- Activation Functions (ml-cheatsheet)
  https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html

- Activation Functions cheat sheet (kaggle)
  https://www.kaggle.com/discussions/getting-started/429326

- Deep Learning Cheatsheet (Stanford)
  https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning

Linear Algebra
--------------

- Essence of Linera Algebra series
  https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab

- Cheat sheet - most basic stuff
  https://www.uio.no/studier/emner/matnat/ifi/IN5550/v19/la.pdf

- Cheat sheet - more advanced
  https://laurentlessard.com/teaching/ece532/cheat_sheet.pdf

- Linear algebra cheat sheet for deep learning + numpy examples
  https://towardsdatascience.com/linear-algebra-cheat-sheet-for-deep-learning-cd67aba4526c

- Matrix Multiplication (Wikipedia)
  https://en.wikipedia.org/wiki/Matrix_multiplication

- Dot product (Wikipedia)
  https://en.wikipedia.org/wiki/Dot_product

- Matrices - Khan Academy
  https://www.khanacademy.org/math/precalculus/x9e81a4f98389efdf:matrices

- Matrix Multiplication Practice
  https://www.shmoop.com/matrices/multiplying-matrix-exercises.html
  https://onlinemschool.com/math/practice/matrix/multiply

- Matrix Calculator
  https://www.mathsisfun.com/algebra/matrix-calculator.html

* A x B = AB
  The element AB[ij] is the result of multiplying A row i with B column j.
  AB is defined only when the number of A columns == number of B rows.

* Identity matrix

Image Processing
----------------

- Kernel (Wikipedia)
  https://en.wikipedia.org/wiki/Kernel_(image_processing)

Graph Theory
------------

- Graph (Wikipedia)
  https://en.wikipedia.org/wiki/Graph_(abstract_data_type)

- Adjacency Matrix (Wikipedia)
  https://en.wikipedia.org/wiki/Adjacency_matrix

- Incidence Matrix (Wikipedia)
  https://en.wikipedia.org/wiki/Incidence_matrix

GenAI and LLM
-------------

- Attention Is All You Need (2017 Google paper)
  https://arxiv.org/pdf/1706.03762

- Transformers, the tech behind LLMs | Deep Learning Chapter 5 (3Blue1Brown)
  https://www.youtube.com/watch?v=wjZofJX0v4M

- Few-shot learning in practice: GPT-Neo and the HuggingFace Accelerated Inference API
  https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api

- EMNLP: Prompt engineering is the new feature engineering
  https://www.amazon.science/blog/emnlp-prompt-engineering-is-the-new-feature-engineering

- Training Compute-Optimal Large Language Models (Chinchilla paper)
  https://arxiv.org/pdf/2203.15556

- BloombergGPT: A Large Language Model for Finance
  https://arxiv.org/pdf/2303.17564

- Extract-0: A Specialized Language Model for Document Information Extraction
  https://arxiv.org/pdf/2509.22906

- Scaling Instruction-Finetuned Language Models (FLAN paper)
  https://arxiv.org/pdf/2210.11416

- HELM Benchmark Leaderboard: Core scenarios
  https://crfm.stanford.edu/helm/classic/latest/#/leaderboard

- The Power of Scale for Parameter-Efficient Prompt Tuning
  https://arxiv.org/pdf/2104.08691

- ReAct: Synergizing Reasoning and Acting in Language Models (ReAct paper)
  https://arxiv.org/pdf/2210.03629

- PAL: Program-aided Language Models (PAL paper)
  https://arxiv.org/pdf/2211.10435

- Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
  https://arxiv.org/pdf/2201.11903

- Constitutional AI: Harmlessness from AI Feedback
  https://arxiv.org/pdf/2212.08073

- Proximal Policy Optimization Algorithms (PPO paper)
  https://arxiv.org/pdf/1707.06347

PyTorch
-------

- PyTorch Tutorials
  https://docs.pytorch.org/tutorials

- PyTorch Examples
  https://github.com/pytorch/examples

- PyTorch 2.0 release (Mar 2023)
  https://pytorch.org/blog/pytorch-2-0-release

- HotChips 2023: "PyTorch 2.0" slides (Aug 2023)
  https://www.hc2023.hotchips.org/assets/program/tutorials/ml/PyTorch%202.0.pdf

- Introducing depyf: mastering torch.compile with ease (May 2024)
  https://pytorch.org/blog/introducing-depyf

- A Walk Through Example of torch.compile
  https://depyf.readthedocs.io/en/latest/walk_through.html

- The Simple Path to PyTorch Graphs: Dynamo and AOT Autograd Explained
  https://medium.com/%40sgurwinderr/pytorch-dynamo-and-aot-autograd-enhancing-performance-and-flexibility-fa18feda5f3a

- Triton language & compiler (by OpenAI)
  https://github.com/triton-lang/triton

- PyTorch execution flow (2025):

  Python code (eager)
        ↓
  TorchDynamo - PyTorch graph capture (uses Python Frame Evaluation API to intercept Python bytecode [PEP 523])
        ↓
  AOTAutograd - forward & backward graph extraction (may be skipped for Inference)
        ↓
  PrimTorch - canonicalize ops to primitive set
        ↓
  TorchInductor - graph compiler. Generates Triton for GPU codegen and C++/OpenMP for CPU. GPU codegen flow:
            ↓
        Triton kernel (Python DSL)
            ↓
        Triton IR
            ↓
        LLVM IR
            ↓
        PTX (NVIDIA's intermediate GPU ISA)
            ↓
        CUDA Driver (JIT compilation)
            ↓
        SASS (native GPU machine code)
            ↓
        Execution on GPU
